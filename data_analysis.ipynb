{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RTE1_dev1_3ways.xml',\n",
       " 'RTE2_test_3ways.xml',\n",
       " 'RTE3_test_3ways.xml',\n",
       " 'RTE3_dev_3ways.xml',\n",
       " 'RTE1_test_3ways.xml',\n",
       " 'RTE2_dev_3ways.xml',\n",
       " 'RTE1_dev2_3ways.xml']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv, os\n",
    "\n",
    "xml_files = [file for file in os.listdir(os.getcwd()+\"/data\") if file.endswith(\".xml\")]\n",
    "xml_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pickle\n",
    "ps = PorterStemmer()\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "hypo = []\n",
    "label = []\n",
    "for file in xml_files:\n",
    "    tree = ET.parse(\"./data/\" + file)\n",
    "    root = tree.getroot()\n",
    "    pairs = root.findall('pair')\n",
    "    for pair in pairs:\n",
    "        if (pair.attrib)['entailment'] != \"UNKNOWN\":\n",
    "            text.append(pair.find('t').text)\n",
    "            hypo.append(pair.find('h').text)\n",
    "            label.append((pair.attrib)['entailment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"text\" : text,\"hypo\" : hypo,\"label\" : label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypo</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crude oil prices rose to $37.80 per barrel</td>\n",
       "      <td>NO</td>\n",
       "      <td>Crude oil for April delivery traded at $37.80 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oracle released a confidential document</td>\n",
       "      <td>NO</td>\n",
       "      <td>Oracle had fought to keep the forms from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strong sales for iTunes in Europe.</td>\n",
       "      <td>YES</td>\n",
       "      <td>iTunes software has seen strong sales in Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Companies selling genetically modified foods d...</td>\n",
       "      <td>NO</td>\n",
       "      <td>All genetically modified food, including soya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coffee drinking has health benefits.</td>\n",
       "      <td>YES</td>\n",
       "      <td>Researchers at the Harvard School of Public He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fiber improves blood sugar control.</td>\n",
       "      <td>YES</td>\n",
       "      <td>Eating lots of foods that are a good source of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rock band Phish holds final concert in Vermont.</td>\n",
       "      <td>YES</td>\n",
       "      <td>Phish disbands after a final concert in Vermon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Denmark and Sweden tie.</td>\n",
       "      <td>YES</td>\n",
       "      <td>Euro-Scandinavian media cheer Denmark v Sweden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>translator kidnapped in Iraq</td>\n",
       "      <td>YES</td>\n",
       "      <td>Iraqi militants said Sunday they would behead ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Green card is now difficult to receive.</td>\n",
       "      <td>YES</td>\n",
       "      <td>Green cards are becoming more difficult to obt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>British servicemen detained</td>\n",
       "      <td>YES</td>\n",
       "      <td>Iran will soon release eight British serviceme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>It takes longer to get green card.</td>\n",
       "      <td>YES</td>\n",
       "      <td>The wait time for a green card has risen from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Coal stocks rise.</td>\n",
       "      <td>YES</td>\n",
       "      <td>Coal company stocks got a lift Monday morning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>British servicemen detained</td>\n",
       "      <td>YES</td>\n",
       "      <td>The Royal Navy servicemen being held captive b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Coal stocks rise.</td>\n",
       "      <td>NO</td>\n",
       "      <td>Total coal stocks with the thermal power stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>California driver's licenses granted to illega...</td>\n",
       "      <td>NO</td>\n",
       "      <td>There are discussions in California and Arizon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>South Korea continues to send troops.</td>\n",
       "      <td>YES</td>\n",
       "      <td>South Korea's deputy foreign minister says his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Clinton's book is a big seller.</td>\n",
       "      <td>NO</td>\n",
       "      <td>Clinton's new book is not big seller here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>private spaceship launches</td>\n",
       "      <td>YES</td>\n",
       "      <td>The privately owned spacecraft only got about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>African polio outbreak feared</td>\n",
       "      <td>YES</td>\n",
       "      <td>World health officials warned yesterday that W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 hypo label  \\\n",
       "0          Crude oil prices rose to $37.80 per barrel    NO   \n",
       "1             Oracle released a confidential document    NO   \n",
       "2                  Strong sales for iTunes in Europe.   YES   \n",
       "3   Companies selling genetically modified foods d...    NO   \n",
       "4                Coffee drinking has health benefits.   YES   \n",
       "5                 Fiber improves blood sugar control.   YES   \n",
       "6     Rock band Phish holds final concert in Vermont.   YES   \n",
       "7                             Denmark and Sweden tie.   YES   \n",
       "8                        translator kidnapped in Iraq   YES   \n",
       "9             Green card is now difficult to receive.   YES   \n",
       "10                        British servicemen detained   YES   \n",
       "11                 It takes longer to get green card.   YES   \n",
       "12                                  Coal stocks rise.   YES   \n",
       "13                        British servicemen detained   YES   \n",
       "14                                  Coal stocks rise.    NO   \n",
       "15  California driver's licenses granted to illega...    NO   \n",
       "16              South Korea continues to send troops.   YES   \n",
       "17                    Clinton's book is a big seller.    NO   \n",
       "18                         private spaceship launches   YES   \n",
       "19                      African polio outbreak feared   YES   \n",
       "\n",
       "                                                 text  \n",
       "0   Crude oil for April delivery traded at $37.80 ...  \n",
       "1   Oracle had fought to keep the forms from being...  \n",
       "2    iTunes software has seen strong sales in Europe.  \n",
       "3   All genetically modified food, including soya ...  \n",
       "4   Researchers at the Harvard School of Public He...  \n",
       "5   Eating lots of foods that are a good source of...  \n",
       "6   Phish disbands after a final concert in Vermon...  \n",
       "7   Euro-Scandinavian media cheer Denmark v Sweden...  \n",
       "8   Iraqi militants said Sunday they would behead ...  \n",
       "9   Green cards are becoming more difficult to obt...  \n",
       "10  Iran will soon release eight British serviceme...  \n",
       "11  The wait time for a green card has risen from ...  \n",
       "12  Coal company stocks got a lift Monday morning ...  \n",
       "13  The Royal Navy servicemen being held captive b...  \n",
       "14  Total coal stocks with the thermal power stati...  \n",
       "15  There are discussions in California and Arizon...  \n",
       "16  South Korea's deputy foreign minister says his...  \n",
       "17         Clinton's new book is not big seller here.  \n",
       "18  The privately owned spacecraft only got about ...  \n",
       "19  World health officials warned yesterday that W...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "import fasttext as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,os\n",
    "\n",
    "def preprocess_text(text):\n",
    "        lem_words = []\n",
    "        doc = nlp(text)\n",
    "        for token in doc:\n",
    "            if token.is_alpha == True:\n",
    "                lem_words.append(token.lemma_)\n",
    "            else:\n",
    "                lem_words.append(\"_value_\")\n",
    "        text = \" \".join(lem_words)\n",
    "        return text\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "df['text'] = df.apply(lambda text: preprocess_text(text[2]), axis=1)\n",
    "df['hypo'] = df.apply(lambda text: preprocess_text(text[0]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypo</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crude oil price rise to _value_ _value_ per ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>crude oil for april delivery trade at _value_ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oracle release a confidential document</td>\n",
       "      <td>0</td>\n",
       "      <td>oracle have fight to keep the form from be rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong sale for itunes in europe _value_</td>\n",
       "      <td>1</td>\n",
       "      <td>itunes software have see strong sale in europe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>company sell genetically modify food do _value...</td>\n",
       "      <td>0</td>\n",
       "      <td>all genetically modify food _value_ include so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee drinking have health benefit _value_</td>\n",
       "      <td>1</td>\n",
       "      <td>researcher at the harvard school of public hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fiber improve blood sugar control _value_</td>\n",
       "      <td>1</td>\n",
       "      <td>eat lot of food that be a good source of fiber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rock band phish hold final concert in vermont ...</td>\n",
       "      <td>1</td>\n",
       "      <td>phish disband after a final concert in vermont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>denmark and sweden tie _value_</td>\n",
       "      <td>1</td>\n",
       "      <td>euro _value_ scandinavian medium cheer denmark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>translator kidnap in iraq</td>\n",
       "      <td>1</td>\n",
       "      <td>iraqi militant say sunday -PRON- would behead ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>green card be now difficult to receive _value_</td>\n",
       "      <td>1</td>\n",
       "      <td>green card be become more difficult to obtain ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                hypo  label  \\\n",
       "0  crude oil price rise to _value_ _value_ per ba...      0   \n",
       "1             oracle release a confidential document      0   \n",
       "2           strong sale for itunes in europe _value_      1   \n",
       "3  company sell genetically modify food do _value...      0   \n",
       "4        coffee drinking have health benefit _value_      1   \n",
       "5          fiber improve blood sugar control _value_      1   \n",
       "6  rock band phish hold final concert in vermont ...      1   \n",
       "7                     denmark and sweden tie _value_      1   \n",
       "8                          translator kidnap in iraq      1   \n",
       "9     green card be now difficult to receive _value_      1   \n",
       "\n",
       "                                                text  \n",
       "0  crude oil for april delivery trade at _value_ ...  \n",
       "1  oracle have fight to keep the form from be rel...  \n",
       "2  itunes software have see strong sale in europe...  \n",
       "3  all genetically modify food _value_ include so...  \n",
       "4  researcher at the harvard school of public hea...  \n",
       "5  eat lot of food that be a good source of fiber...  \n",
       "6  phish disband after a final concert in vermont...  \n",
       "7  euro _value_ scandinavian medium cheer denmark...  \n",
       "8  iraqi militant say sunday -PRON- would behead ...  \n",
       "9  green card be become more difficult to obtain ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_data(df):\n",
    "        a, b, c,d = model_selection.train_test_split(df['text'], df['label'],random_state=1234)\n",
    "        aa, bb, c,d = model_selection.train_test_split(df['hypo'], df['label'],random_state=1234)\n",
    "        return a , b , aa, bb , c , d\n",
    "train_t, valid_t, train_h, valid_h, train_y, valid_y = split_training_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2749    at the southeastern tip of the city _value_ xo...\n",
       "1298    the bolan pass be a gap through the toba kakar...\n",
       "1619    mr carstens leave -PRON- job as imf _value_ de...\n",
       "1141    a specialist firm on the new york stock exchan...\n",
       "1692    the directive _value_ issue by vietnam _value_...\n",
       "301     at the same time _value_ old mutual asset mana...\n",
       "2448    sani _value_ seat can offset the rise cost of ...\n",
       "2086    de la rue be the world _value_ large commercia...\n",
       "1023    two document that a former fbi agent say -PRON...\n",
       "1763    today _value_ highlight in history _value_ on ...\n",
       "83      passion surround germany _value_ final match a...\n",
       "2585    india _value_ an enchanting country situate in...\n",
       "216     speak to newsman in jakarta today _value_ hun ...\n",
       "1838    mark said and philip dick _value_ two member o...\n",
       "79      wal _value_ mart have receive a lot of negativ...\n",
       "2347    the controversy become more desperate _value_ ...\n",
       "2670    a cataclysmic starquake be think to have cause...\n",
       "527     recognize as the eighth deep lake in the world...\n",
       "2704    radical jordanian cleric _value_ abu qatada _v...\n",
       "190     authority in brazil say that more than _value_...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2749    xochimilco be a popular tourist attraction bec...\n",
       "1298    the british army cross the toba kakar range of...\n",
       "1619    mr carstens lose -PRON- job as imf _value_ dep...\n",
       "1141    one judge say that the nearly half million dol...\n",
       "1692    the regulation be the late one in a string of ...\n",
       "301      barrow hanley be a competitor of pacific _value_\n",
       "2448                    the cost of paper be rise _value_\n",
       "2086    de la rue make much of the world _value_ money...\n",
       "1023      martin luther king be murder in _value_ _value_\n",
       "1763    lee harvey oswald kill president john _value_ ...\n",
       "83         a man be stab because of a soccer game _value_\n",
       "2585              india be on the asian continent _value_\n",
       "216             hun sen represent the khmer rouge _value_\n",
       "1838    mark said work for ontario bradley first air _...\n",
       "79      wal _value_ mart face allegation for underpay ...\n",
       "2347    the kuiper belt be nine billion mile from the ...\n",
       "2670    the flash of radiation on december _value_ _va...\n",
       "527      lake tahoe be the deep lake in the world _value_\n",
       "2704    _value_ foreign national be a threat to britia...\n",
       "190     authority in brazil hold _value_ people as hos...\n",
       "Name: hypo, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_h.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2749    1\n",
       "1298    1\n",
       "1619    0\n",
       "1141    1\n",
       "1692    1\n",
       "301     0\n",
       "2448    1\n",
       "2086    1\n",
       "1023    1\n",
       "1763    1\n",
       "83      1\n",
       "2585    1\n",
       "216     0\n",
       "1838    1\n",
       "79      1\n",
       "2347    1\n",
       "2670    1\n",
       "527     0\n",
       "2704    1\n",
       "190     0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       crude oil price rise to _value_ _value_ per ba...\n",
       "1       oracle release a confidential document oracle ...\n",
       "2       strong sale for itunes in europe _value_ itune...\n",
       "3       company sell genetically modify food do _value...\n",
       "4       coffee drinking have health benefit _value_ re...\n",
       "5       fiber improve blood sugar control _value_ eat ...\n",
       "6       rock band phish hold final concert in vermont ...\n",
       "7       denmark and sweden tie _value_ euro _value_ sc...\n",
       "8       translator kidnap in iraq iraqi militant say s...\n",
       "9       green card be now difficult to receive _value_...\n",
       "10      british serviceman detain iran will soon relea...\n",
       "11      -PRON- take long to get green card _value_ the...\n",
       "12      coal stock rise _value_ coal company stock get...\n",
       "13      british serviceman detain the royal navy servi...\n",
       "14      coal stock rise _value_ total coal stock with ...\n",
       "15      california driver _value_ license grant to ill...\n",
       "16      south korea continue to send troop _value_ sou...\n",
       "17      clinton _value_ book be a big seller _value_ c...\n",
       "18      private spaceship launch the privately own spa...\n",
       "19      african polio outbreak fear world health offic...\n",
       "20      wal _value_ mart sue for sexual discrimination...\n",
       "21      _value_ supreme court in favor of same _value_...\n",
       "22      prime minister target for assassination kurdis...\n",
       "23      wal _value_ mart face a sex _value_ discrimina...\n",
       "24      american accuse of espionage a cuban american ...\n",
       "25      american accuse of espionage a syrian _value_ ...\n",
       "26      daily telegraph be sell _value_ the daily tele...\n",
       "27      baby elephant bear on november _value_ _value_...\n",
       "28      baby elephant bear the _value_ _value_ old _va...\n",
       "29      bee sting can be fatal wasp and bee sting can ...\n",
       "                              ...                        \n",
       "2893    harvey weinstein be the co _value_ chairman of...\n",
       "2894    open day of the stock of _value_ rise _value_ ...\n",
       "2895    a summit between europe and japan be take plac...\n",
       "2896    the first heart transplant in britian be perfo...\n",
       "2897    dead dolphin _value_ turtle and whale have be ...\n",
       "2898    the _value_ grandmother hypothesis _value_ sug...\n",
       "2899    the kidnapper pay compensation to the victim o...\n",
       "2900    regan be almost assassinate in _value_ _value_...\n",
       "2901    _value_ blame a court decision that will becau...\n",
       "2902    infertile woman can not produce child _value_ ...\n",
       "2903    infertile woman be vital for successful child ...\n",
       "2904    there be a fire in alaska _value_ cool _value_...\n",
       "2905    the sec _value_ new rule will give board indep...\n",
       "2906    norwegian employer cause oil price to rise _va...\n",
       "2907    male fertility may be affect by use of a mobil...\n",
       "2908    eu leader find an agreement about a candidate ...\n",
       "2909    saginaw police mistakenly go to the wrong hous...\n",
       "2910    medicare will choose _value_ percent of applic...\n",
       "2911    the terrorist may have cause suicide attack an...\n",
       "2912    the freedom tower will be the world _value_ ta...\n",
       "2913    the judge approve of sex _value_ discriminatio...\n",
       "2914    between _value_ and _value_ man be be hold at ...\n",
       "2915    al _value_ jazeera be an arabic _value_ langua...\n",
       "2916    a lawsuit be file against wal _value_ mart _va...\n",
       "2917    jessica litman be a law professor _value_ jess...\n",
       "2918    ralph fiennes will play harry potter in the ne...\n",
       "2919    suncream design for child protect at the level...\n",
       "2920    kerry watch firework _value_ after watch firew...\n",
       "2921    cheney curse at _value_ patrick leahy _value_ ...\n",
       "2922    _value_ people kill in karachi bomb attack _va...\n",
       "Name: combined, Length: 2923, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"combined\"] = df.apply(lambda x : \"{} {}\".format(x[0] , x[2]),axis=1)\n",
    "df[\"combined\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_embeddings_and_sequences(train_df,train_t,valid_t,train_h,valid_h):\n",
    "\n",
    "        embeddings_index = {}\n",
    "        for i, line in enumerate(open('data/subword.vec'.format(os.getcwd()))):\n",
    "            values = line.split()\n",
    "            embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "        token_t = text.Tokenizer()\n",
    "        token_t.fit_on_texts(train_df['combined'])\n",
    "        word_index = token_t.word_index\n",
    "        max_len_t = train_df.text.map(len).max()\n",
    "        train_seq_t = sequence.pad_sequences(token_t.texts_to_sequences(train_t), maxlen=max_len_t)\n",
    "        valid_seq_t = sequence.pad_sequences(token_t.texts_to_sequences(valid_t), maxlen=max_len_t)\n",
    "        train_seq_h = sequence.pad_sequences(token_t.texts_to_sequences(train_h), maxlen=max_len_t)\n",
    "        valid_seq_h = sequence.pad_sequences(token_t.texts_to_sequences(valid_h), maxlen=max_len_t)\n",
    "        embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "        for word, i in word_index.items():\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "\n",
    "        return train_seq_t, valid_seq_t, word_index, embedding_matrix,train_seq_h, valid_seq_h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_t, valid_seq_t, word_index, embedding_matrix,train_seq_h, valid_seq_h= making_embeddings_and_sequences(df,train_t, valid_t,train_h, valid_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import model_from_json\n",
    "from sklearn import model_selection\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_the_model(len_word_index,embedding_matrix,num_classes):\n",
    "        input_t = Input(shape=(743,), dtype='float32')\n",
    "        input_h = Input(shape=(743,), dtype='float32')\n",
    "        t_input = Embedding(len_word_index + 1, 300, weights=[embedding_matrix], trainable=False)(input_t)\n",
    "        bi_t = Bidirectional(LSTM(units=5))(t_input)\n",
    "        bi_t = Dropout(0.5)(bi_t)\n",
    "        h_input = Embedding(len_word_index + 1, 300, weights=[embedding_matrix], trainable=False)(input_h)\n",
    "        bi_h = Bidirectional(LSTM(units=5))(h_input)\n",
    "        bi_h = Dropout(0.5)(bi_h)\n",
    "        conc = keras.layers.concatenate([bi_t, bi_h],axis=-1)\n",
    "        x = Dense(units=128,activation=\"relu\")(conc)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(units=64,activation=\"relu\")(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(units=32,activation=\"relu\")(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(units=num_classes,activation=\"softmax\")(x)\n",
    "        model = Model(inputs=[input_t, input_h], outputs=[x])\n",
    "        adam = keras.optimizers.Adam(lr=0.0001, decay=0.0000001, amsgrad=False)\n",
    "        model.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "Epoch 1/1\n",
      "2192/2192 [==============================] - 24s 11ms/step - loss: 0.5675 - acc: 0.7724\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model_name = \"lstm_combined_text_simple\"\n",
    "num_classes = np.max(train_y) + 1\n",
    "print(num_classes)\n",
    "train_y = utils.to_categorical(train_y, num_classes)\n",
    "print(train_y)\n",
    "valid_y = utils.to_categorical(valid_y, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2192/2192 [==============================] - 25s 11ms/step - loss: 0.6911 - acc: 0.5753\n",
      "Epoch 2/10\n",
      "2192/2192 [==============================] - 21s 9ms/step - loss: 0.6867 - acc: 0.6756\n",
      "Epoch 3/10\n",
      "2192/2192 [==============================] - 21s 10ms/step - loss: 0.6819 - acc: 0.7400\n",
      "Epoch 4/10\n",
      "2192/2192 [==============================] - 21s 10ms/step - loss: 0.6761 - acc: 0.7559\n",
      "Epoch 5/10\n",
      "2192/2192 [==============================] - 21s 10ms/step - loss: 0.6706 - acc: 0.7678\n",
      "Epoch 6/10\n",
      "2192/2192 [==============================] - 21s 9ms/step - loss: 0.6635 - acc: 0.7719\n",
      "Epoch 7/10\n",
      "2192/2192 [==============================] - 21s 9ms/step - loss: 0.6545 - acc: 0.7737\n",
      "Epoch 8/10\n",
      "2192/2192 [==============================] - 21s 10ms/step - loss: 0.6447 - acc: 0.7765\n",
      "Epoch 9/10\n",
      "2192/2192 [==============================] - 21s 10ms/step - loss: 0.6343 - acc: 0.7787\n",
      "Epoch 10/10\n",
      "2192/2192 [==============================] - 22s 10ms/step - loss: 0.6230 - acc: 0.7769\n"
     ]
    }
   ],
   "source": [
    "model = create_the_model(len(word_index),embedding_matrix,num_classes)\n",
    "model.fit([train_seq_t,train_seq_h], train_y, epochs=10, batch_size=256)\n",
    "#validation_data=([self.data_processing.valid_seq_t,self.data_processing.valid_seq_h], self.data_processing.valid_y)\n",
    "y_predict = model.predict([valid_seq_t,valid_seq_h])\n",
    "#print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26834384 0.7316562 ]\n",
      " [0.2664134  0.73358667]\n",
      " [0.2602133  0.7397868 ]\n",
      " ...\n",
      " [0.2646246  0.7353754 ]\n",
      " [0.26240775 0.7375923 ]\n",
      " [0.2626068  0.73739314]]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contradiction",
   "language": "python",
   "name": "contradiction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
